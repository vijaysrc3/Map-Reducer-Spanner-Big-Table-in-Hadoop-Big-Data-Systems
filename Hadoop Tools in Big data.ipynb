{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-aling:center;color:Navy'>  Big Data Systems - Fall 2021  </h1>\n",
    "<h1 style='text-aling:center;color:Navy'>  Assignment 1  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is focused on Hadoop as well as Big Data Storage Systems. In particular we will work with the following: \n",
    "- Map-Reduce \n",
    "- Spanner DB\n",
    "- Bigtable\n",
    "\n",
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "# When you log-in please hit return (not shift + return) after typing in your email\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('Assignment1.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission Deadline: This assignment is due Monday, Sep 29 at 11:59 P.M.\n",
    "\n",
    "A few notes before you start:\n",
    "\n",
    "- Directly sharing answers is not okay, but discussing problems with other students is encouraged.\n",
    "\n",
    "- You should start early so that you have time to get help if you're stuck.\n",
    "\n",
    "- Before continuing the assignment, select \"Save and Checkpoint\" in the File menu and then execute the submit cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to okpy.org and flag the correct version. There will be another submit cell at the end of the assignment when you finish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Let's do some preparations to setup the system for your work. First, open a terminal: </span>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "#### Right click on the \"jupyterhub\" logo in the top left corner and open in a new tab\n",
    "\n",
    "In order to do this assignment, you will need to open the terminal.\n",
    "\n",
    "#### Click on New >> Terminal\n",
    "\n",
    "You will see the terminal.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Now we need to ssh into \"node5\" of the computing platform of the course: </span>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "#### In your terminal, run:\n",
    "```\n",
    "sudo apt get update\n",
    "```\n",
    "#### Then run:\n",
    "```\n",
    "sudo apt-get install openssh-client\n",
    "```\n",
    "##### Select yes. <br>\n",
    "\n",
    "#### Once that is complete, run:\n",
    "```\n",
    "ssh ucdenver@node5\n",
    "password: ucdenver\n",
    "```\n",
    "#### Make a directory in the hadoop environment:\n",
    "```\n",
    "sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/<firstname_lastname>\n",
    "```\n",
    "```\n",
    "e.g: sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/khang_nguyen\n",
    "```\n",
    "You can see your directory here http://node5.ucdenver.pvt:50070/explorer.html#/user/<firstname_lastname>\n",
    "\n",
    "#### Make a subdirectory inside <firstname_lastname> in the hadoop environment:\n",
    "```\n",
    "sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/<firstname_lastname>/input\n",
    "e.g: sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs  -mkdir /user/khang_nguyen/input\n",
    "```\n",
    "#### Make a directory with your name:\n",
    "```\n",
    "mkdir <firstname_lastname>\n",
    "e.g: mkdir khang_nguyen\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid purple; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"font-size:35px;color:#3665af\">Section 1: Word Count Example </span>\n",
    "***\n",
    "### Map/Reduce Classes\n",
    "We have three classes available:<br>\n",
    "- WordCount.Java &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;     *Main program* <br>\n",
    "- WordcountMapper.java &emsp;&emsp;&emsp;&emsp;                 *Implementation of the Map* <br> \n",
    "- WordCountReducer.java &emsp;&emsp;&emsp;&nbsp;                *Implementation of the Reduce* <br>\n",
    "\n",
    "<br>\n",
    "Take a look at the Main program, try to identify where the files are loaded.\n",
    "<br>\n",
    "In the same fashion, inspect the Mapper and the Reducer class to identify the emit and the collect steps on the code. \n",
    "<br> \n",
    "Now, let's run the WordCount:\n",
    "  \n",
    "  \n",
    "## <span style=\"color:green\">Transfer files: </span>\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">  \n",
    "    \n",
    "#### Transfer the following files to ucdenver@node5/\\<firstname_lastname> folder:\n",
    "    WordCount.Java\n",
    "    WordcountMapper.java\n",
    "    WordCountReducer.java\n",
    "    hamlet.txt\n",
    "    \n",
    "</div>\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> You can transfer files using WinSCP (Host name: node5, username: ucdenver, password: ucdenver)\n",
    "</div>\n",
    "    \n",
    "    \n",
    "## <span style=\"color:green\">Compile the program: </span>\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">    \n",
    "    \n",
    "#### In your terminal, run:\n",
    "    \n",
    "``` \n",
    "cd <firstname_lastname>\n",
    "e.g: cd khang_nguyen\n",
    "    \n",
    "ucdenver@node5:~/khang_nguyen$ export HADOOP_CLASSPATH=$(/home/hdoop/hadoop-2.10.1/bin/hadoop classpath)\n",
    "ucdenver@node5:~/khang_nguyen$ javac -classpath ${HADOOP_CLASSPATH}  *.java\n",
    "```\n",
    "#### Making the JAR:\n",
    "```\n",
    "ucdenver@node5:~/khang_nguyen$ jar cf WordCount.jar WordCount*.class\n",
    "```\n",
    "#### Upload file to Hadoop file system:\n",
    "```\n",
    "ucdenver@node5:~/khang_nguyen$ sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop fs -put hamlet.txt /user/<firstname_lastname>/input \n",
    "    \n",
    "e.g: ucdenver@node5:~/khang_nguyen$ sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop fs -put hamlet.txt /user/khang_nguyen/input \n",
    "```\n",
    "#### Run the hadoop Program:\n",
    "```\n",
    "sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop jar WordCount.jar WordCount /user/<firstname_lastname>/input /user/<firstname_lastname>/output/1\n",
    "\n",
    "e.g: sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop jar WordCount.jar WordCount /user/khang_nguyen/input /user/khang_nguyen/output/1\n",
    "```    \n",
    "#### Verify the output here:\n",
    "```\n",
    "http://node5.ucdenver.pvt:50070/explorer.html#/user/<firstname_lastname>\n",
    "\n",
    "e.g: http://node5.ucdenver.pvt:50070/explorer.html#/user/khang_nguyen\n",
    "```\n",
    "### Paste your output from the Terminal in the next cell.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "#### Using the \"_**hdfs dfs -cat**_\" bring the files in the output directory of the HDFS:\n",
    "\n",
    "```\n",
    "sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs -cat /user/<firstname_lastname>/output/1/*\n",
    "    \n",
    "e.g. sudo -u hdoop /home/hdoop/hadoop-2.10.1/bin/hadoop dfs -cat /user/khang_nguyen/output/1/*\n",
    "```\n",
    "\n",
    "#### Using the \"_**head**_ command\" extract the first 10 rows of one of the output files. \n",
    "Hint: Linux Pipeline command \n",
    "## Paste your output in the next cell\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OUTPUT Goes HERE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspect the output by using the commands cat, grep, tail, head.\n",
    "- Did you notice any issues on how the counting was done? For example, look a the word \"them\". Was the output as you expected to be?\n",
    "- If not, how can you address the problem. \n",
    "\n",
    "## Write your answers to the aforementioned questions in the next cell. You don't need to implement your solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px solid red; margin-top: 20px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "## <span style=\"color:RED\">Exercise: </span> Department monthly sales\n",
    "\n",
    "<hr style=\"border-top: 1px solid red; margin-top: 20px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "Based on the map-reduce example above, do the proper modifications to solve the following problem:\n",
    "<br>\n",
    "We are going to be using the Walmart Store Sales Forecasting competition training dataset available [here](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data). Considering this dataset, you should produce a monthly summary of the sales per department. <br>\n",
    "So you output should be like:\n",
    "<pre>\n",
    "dept-year-month:$$$\n",
    "</pre>\n",
    "1. Download the training dataset and upload it to your server for processing (using WinSCP again). Be careful with the paths you use. <br>\n",
    "2. Using the three provided java classes as a template, create three new classes: <i>Walmart.java, WalmartMapper.java, WalmartReducer.java</i> with the proper code. <br>\n",
    "3. Fill in the following and make sure to keep saving your work.\n",
    "\n",
    "Now, answer the following questions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Place your map function in the next cell:  <span style=\"font-size:12px\">(Only the function) </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Place your reduce function in the next cell:  <span style=\"font-size:12px\">(Only the function) </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Place your running output in the next cell:  <span style=\"font-size:12px\"> </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Place the first 10 rows of your exit in the next cell:  <span style=\"font-size:12px\">(Hint: take a look at the _wc_ linux command) </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NB:</b> CLOSE YOUR TERMINAL BEFORE CONTINUING TO SECTION 2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid purple; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"font-size:35px;color:#3665af\">Section 2: Spanner </span>\n",
    "\n",
    "<hr>\n",
    "In this section we will practice how to use Google's Spanner database. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> Your Google cloud account should be ready to deploy services. See the GoogleCloud_Setup document on the Canvas assignment page.\n",
    "</div>\n",
    "\n",
    "\n",
    "### <span style=\"color:green\"> Create a Spanner Instance:</span>\n",
    "<span style=\"font-size:15px;color:purple\">Detailed instructions in the document </span>\n",
    "\n",
    "- Create a spanner instace, and annotate the Instance ID. \n",
    "- We will use lab1-section2 as instance id in this assignment; if you are using another id, you need to change it in the connection settings. \n",
    "- For this test, configuring one node will suffice. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Install the Python Client: </span>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "We need to have the google-cloud library installed in our system.<br>\n",
    "Open the terminal under <b>New >> Terminal</b><br>\n",
    "Then execute the following pip commands to install the client library. \n",
    "    \n",
    "\n",
    "\n",
    "``` bash\n",
    "$> pip install google\n",
    "$> pip install google-cloud\n",
    "$> pip install google-cloud-datastore --user\n",
    "$> pip install google-cloud-spanner\n",
    "$> pip install google-api-core\n",
    "$> pip install google-cloud-storage\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NB:</b> PLEASE RESTART THE KERNEL (Kernel -> Restart)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Get the Service Account File:</span>\n",
    "As mentioned in the cloud setup instructions, you need to generate a token file so you will be able to connect to spanner. Refer to that document for help. <br>\n",
    "Here is the summary of the steps. \n",
    "1. Go to APIS & Services\n",
    "2. Go to Credentials\n",
    "3. Select Create Credentials, and choose Service account key.\n",
    "4. Select Compute Engine default service account and Key type JSON. Then Create. \n",
    "5. Pick the file that was automatically downloaded, and store it in your Assignment1 directory on jupyterhub. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Beofore you perform the excercise for this section (at the bottom of this section), let's run through an example. Run the following cells to review the example: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud Client Library.\n",
    "from google.cloud import spanner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NB:</b> Replace the \"bigdatasystems-fall2021-325819-e64d042b5422.json\" name below with the one you copied to your Assignment1 directory (bigdata > Assignment1 > *.json)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"bigdatasystems-fall2021-325819-e64d042b5422.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about creating instances and using Spanner with Python at [Google Documentation](https://cloud.google.com/spanner/docs/getting-started/python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explicit():\n",
    "    ## Function to connect to spanner\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Explicitly use service account credentials by specifying the private key\n",
    "    # file.\n",
    "    storage_client = storage.Client.from_service_account_json(JSON_SERVICE_KEY)\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get help about authentication at [Google Documentation](https://cloud.google.com/docs/authentication/production#auth-cloud-explicit-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Using Spanner Client:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate a client.\n",
    "spanner_client = spanner.Client()\n",
    "\n",
    "# Your Cloud Spanner instance ID.\n",
    "instance_id = 'lab1-section2'\n",
    "\n",
    "# Get a Cloud Spanner instance by ID.\n",
    "instance = spanner_client.instance(instance_id)\n",
    "\n",
    "# Your Cloud Spanner database ID.\n",
    "database_id = 'lab1-db'           # If you did not create the database already, createit using the cloud console\n",
    "\n",
    "# Get a Cloud Spanner database by ID.\n",
    "database = instance.database(database_id)\n",
    "\n",
    "# Execute a simple SQL statement.\n",
    "with database.snapshot() as snapshot:\n",
    "    results = snapshot.execute_sql('SELECT current_date')\n",
    "\n",
    "    for row in results:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't recevie an error and the current date was displayed, it means that at this point we're connected to our Spanner database.<rb>\n",
    "\n",
    "#### <span style=\"color:Green\">Create a couple of tables:</span>\n",
    "\n",
    "This may take a minute. If you use your google cloud dashboard, you can see the two new tables as you refresh the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation =database.update_ddl(ddl_statements=[\n",
    "    \"\"\"CREATE TABLE Singers (\n",
    "        SingerId     INT64 NOT NULL,\n",
    "        FirstName    STRING(1024),\n",
    "        LastName     STRING(1024),\n",
    "        SingerInfo   BYTES(MAX)\n",
    "    ) PRIMARY KEY (SingerId)\"\"\"\n",
    "    ,\n",
    "    \"\"\"CREATE TABLE Albums (\n",
    "        SingerId     INT64 NOT NULL,\n",
    "        AlbumId      INT64 NOT NULL,\n",
    "        AlbumTitle   STRING(MAX)\n",
    "    ) PRIMARY KEY (SingerId, AlbumId),\n",
    "      INTERLEAVE IN PARENT Singers ON DELETE CASCADE\"\"\"\n",
    "])\n",
    "\n",
    "# operation = database.create()\n",
    "\n",
    "print('Waiting for operation to complete...')\n",
    "operation.result()\n",
    "\n",
    "print('Created tables in database {} on instance {}'.format( database_id, instance_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION:\n",
    "**_In which line the command that creates the database is actually executed on Spanner?_** Explain briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Now let's insert some data:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Inserts sample data into the given database.\n",
    "   The database and table must already exist.\n",
    "\"\"\"\n",
    "\n",
    "with database.batch() as batch:\n",
    "    batch.insert(\n",
    "        table='Singers',\n",
    "        columns=('SingerId', 'FirstName', 'LastName',),\n",
    "        values=[\n",
    "            (1, u'Marc', u'Richards'),\n",
    "            (2, u'Catalina', u'Smith'),\n",
    "            (3, u'Alice', u'Trentor'),\n",
    "            (4, u'Lea', u'Martin'),\n",
    "            (5, u'David', u'Lomond')])\n",
    "    batch.commit\n",
    "    \n",
    "    batch.insert(\n",
    "        table='Albums',\n",
    "        columns=('SingerId', 'AlbumId', 'AlbumTitle',),\n",
    "        values=[\n",
    "            (1, 1, u'Total Junk'),\n",
    "            (1, 2, u'Go, Go, Go'),\n",
    "            (2, 1, u'Green'),\n",
    "            (2, 2, u'Forever Hold Your Peace'),\n",
    "            (2, 3, u'Terrified')])\n",
    "    batch.commit\n",
    "print('Inserted data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION:\n",
    "**_How many statements were executed in Spanner?_** Explain briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Here we query the database:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Queries sample data from the database using SQL.\"\"\"\n",
    "\n",
    "\n",
    "with database.snapshot() as snapshot:\n",
    "    results = snapshot.execute_sql(\n",
    "        'SELECT SingerId, AlbumId, AlbumTitle FROM Albums')\n",
    "    \n",
    "    display(results)\n",
    "    \n",
    "    for row in results:\n",
    "        display(row)\n",
    "        print('SingerId: {}, AlbumId: {}, AlbumTitle: {}'.format(*row))\n",
    "        #print(\"SingerId: \",row[0],\", AlbumId: \",row[1],\", AlbumTitle: \",row[2], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTIONS:\n",
    "1. **What kind of object is _results_?**\n",
    "2. **What kind of object is _row_?**\n",
    "3. **How is row being accessed?** (Tip: take a look at the commented line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>\n",
    "1. answer\n",
    "2. answer\n",
    "3. answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reads sample data from the database.\"\"\"\n",
    "\n",
    "with database.snapshot() as snapshot:\n",
    "    keyset = spanner.KeySet(all_=True)\n",
    "    results = snapshot.read(\n",
    "        table='Albums',\n",
    "        columns=('SingerId', 'AlbumId', 'AlbumTitle',),\n",
    "        keyset=keyset,)\n",
    "\n",
    "    for row in results:\n",
    "        print('SingerId: {}, AlbumId: {}, AlbumTitle: {}'.format(*row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTIONS\n",
    "**_What is the difference between the first and second part of the code?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Now let's load some interesting data:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate a client.\n",
    "spanner_client = spanner.Client()\n",
    "\n",
    "# Your Cloud Spanner instance ID.\n",
    "instance_id = 'lab1-section2'\n",
    "\n",
    "# Get a Cloud Spanner instance by ID.\n",
    "instance = spanner_client.instance(instance_id)\n",
    "\n",
    "# Your Cloud Spanner database ID.\n",
    "database_id = 'lab1-db'                             ## Create new Database\n",
    "\n",
    "# Get a Cloud Spanner database by ID.\n",
    "database = instance.database(database_id)\n",
    "\n",
    "# Execute a simple SQL statement.\n",
    "with database.snapshot() as snapshot:\n",
    "    results = snapshot.execute_sql('SELECT current_date')\n",
    "\n",
    "    for row in results:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time()\n",
    "operation =database.update_ddl(ddl_statements=[\n",
    "    \"\"\"CREATE TABLE RadiationMeasurements\n",
    "        (\n",
    "           CapturedTime timestamp,\n",
    "           Latitude float64,\n",
    "           Longitude float64,\n",
    "           Value float64,\n",
    "           Unit String(2048),\n",
    "           Location String(2048),\n",
    "           DeviceID String(2048),\n",
    "           MD5Sum String(2048),\n",
    "           Height String(2048),\n",
    "           Surface String(2048),\n",
    "           Radiation String(2048),\n",
    "           UploadedTime timestamp,\n",
    "           LoaderID float64\n",
    "        )PRIMARY KEY (CapturedTime,Latitude,Longitude,Location,UploadedTime,MD5Sum)\"\"\"\n",
    "])\n",
    "\n",
    "# operation = database.create()\n",
    "\n",
    "print('Waiting for operation to complete...')\n",
    "operation.result()\n",
    "\n",
    "print('Created tables in database {} on instance {}'.format(\n",
    "    database_id, instance_id))\n",
    "\n",
    "end_time=time()\n",
    "\n",
    "print (\"run time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Measures        = pd.read_csv(\"radiation.measurements.sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Measures.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData=[]\n",
    "for index,row in df_Measures[0:5].iterrows():\n",
    "    aDateTime = datetime.datetime.strptime(row[\"Captured Time\"], '%Y-%m-%d %H:%M:%S')\n",
    "    display('Row: {}, Timestamp: {} Lat/Lon:{}/{}'.format(index,aDateTime,row[\"Latitude\"],row[\"Longitude\"]))\n",
    "    myData.append( (index,aDateTime)  )\n",
    "myData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ****************************************************************\n",
    "#     TO-DO: Write here a while/for to insert the Primary key data for the first 10 rows. \n",
    "#     ****************************************************************\n",
    "\n",
    "# --Hints:\n",
    "#     Adapt the code from the sample. \n",
    "#     Generate an array inserting tuples (you should use an array and the function append )\n",
    "\n",
    "\n",
    "### Write your code here.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#5DB664\">DELETE YOUR SPANNER INSTANCE AS WHEN YOU FINISH WITH REVIEW OF THE ABOVE EXAMPLE!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px solid red; margin-top: 20px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "# <span style=\"color:RED\">Exercise: </span> Yelp Dataset\n",
    "\n",
    "<hr style=\"border-top: 1px solid red; margin-top: 20px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "Similar to the example above, we are going to be using the Yelp competition dataset available [here](https://www.kaggle.com/yelp-dataset/yelp-dataset/data). <br>\n",
    "You should:\n",
    "1. Download the dataset to your machine.\n",
    "2. Create a new database.\n",
    "3. Create the tables necessary, with the proper interleaving configuration to store the business and reviews.\n",
    "4. Load the yelp_business dataset.\n",
    "5. Load 10% of the yelp_review dataset.\n",
    "\n",
    "Hints:\n",
    "- You probably want to do several batchs. You can do that by using the **[start:end]** operator for the dataframes. \n",
    "- You may need to review the documentation for the [Spanner SQL](https://cloud.google.com/spanner/docs/query-syntax)\n",
    "\n",
    "## Questions:\n",
    "1. Report the time for loading each dataset.\n",
    "2. Compare the time to load the rows for the business and the reviews datasets.\n",
    "3. List the top 10 better/most rated businesses in Colorado. To simplify this, let's assume that the best rated business is the one with the higher sum of ratings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACE YOUR CODE STARTING THIS POINT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid purple; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <span style=\"font-size:35px;color:#3665af\">Section 3: Bigtable </span>\n",
    "\n",
    "<hr>\n",
    "In this section we will practice how to use Google's Bigtable database. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> Your Google cloud account should be ready to deploy services. See the GoogleCloud_Setup document on the Canvas assignment page.\n",
    "</div>\n",
    "\n",
    "### <span style=\"color:green\"> Create a Bigtable Instance:</span>\n",
    "<span style=\"font-size:15px;color:purple\">Detailed instructions in the document </span>\n",
    "- Create a development Bigtable instace, and annotate the Instance ID. \n",
    "- We will use \"lab1-section3\" instance id in this assignment; if you are using another id, you need to change in the connection settings. \n",
    "- For this test, use a development instance, which has only one node but is way cheaper. \n",
    "\n",
    "\n",
    "### <span style=\"color:green\"> Get the Service Account File:</span>\n",
    "\n",
    "As mentioned in the cloud set up instructions, you need to generate a token file so you will be able to connect to bigtable. Refer to that document for help.\n",
    "\n",
    "Documentation [here](http://google-cloud-python.readthedocs.io/en/latest/bigtable/usage.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Installing the Python Client: </span>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "We need to have the google cloud library installed in our system.<br>\n",
    "Execute the following pip command in your terminal to install the client library. \n",
    "\n",
    "```\n",
    "$> pip install google-cloud-bigtable --user\n",
    "$> pip install google-cloud-happybase\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Beofore you perform the excercise for this section (at the bottom of this section), let's run through an example. Run the following cells to review the example: </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NB:</b> Replace the \"bigdatasystems-fall2021-325819-e64d042b5422.json\" name below with the one you copied to your Assignment1 directory (bigdata > Assignment1 > *.json)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"bigdatasystems-fall2021-325819-e64d042b5422.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about creating instances and using Spanner with Python at [Google Documentation](https://cloud.google.com/spanner/docs/getting-started/python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explicit():\n",
    "    ## Function to connect to spanner\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Explicitly use service account credentials by specifying the private key\n",
    "    # file.\n",
    "    storage_client = storage.Client.from_service_account_json(JSON_SERVICE_KEY)\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get help about authentication at [Google Documentation](https://cloud.google.com/docs/authentication/production#auth-cloud-explicit-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Using Bigdata Client:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_id = \"lab1-section3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud Client Library.\n",
    "from google.cloud import bigtable\n",
    "\n",
    "# The client must be created with admin=True because it will create a table.\n",
    "client     = bigtable.Client(admin=True)\n",
    "instance   = client.instance(instance_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't receive an error, it means that at this point we're connected to our Bigtable database else you should follow instruction in Google Cloud document<rb>\n",
    "\n",
    "#### <span style=\"color:Green\">Let's create a table:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name  = \"greetings\"\n",
    "print('Creating the {} table.'.format(table_name))\n",
    "\n",
    "table = instance.table(table_name)\n",
    "table.create()\n",
    "\n",
    "column_family_name = 'cf1'\n",
    "cf1 = table.column_family(column_family_name)\n",
    "cf1.create()\n",
    "\n",
    "#table.delete()  #to delete the table.\n",
    "\n",
    "print(\"done!\")\n",
    "### WARNING\n",
    "#\n",
    "## You will get an error the first time saying that you did not enable admin api. \n",
    "## A link will be given. Follow it and enable the API And retry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Now we insert the data:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writing some greetings to the table.')\n",
    "column_name = 'greeting'.encode('utf-8')\n",
    "greetings = [\n",
    "    'Hello World!',\n",
    "    'Hello Cloud Bigtable!',\n",
    "    'Hello Bigtable with Python!',\n",
    "]\n",
    "\n",
    "for i, value in enumerate(greetings):\n",
    "    row_key = 'greeting{}'.format(i)\n",
    "    row = table.row(row_key)\n",
    "    row.set_cell(   \n",
    "                    column_family_name,\n",
    "                    column_name,\n",
    "                    value.encode('utf-8')\n",
    "                )\n",
    "    row.commit()\n",
    "    \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Next we read the data:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting a single greeting by row key.')\n",
    "key = 'greeting0'\n",
    "\n",
    "row = table.read_row(key.encode('utf-8'))\n",
    "\n",
    "value = row.cells[column_family_name][column_name][0].value\n",
    "\n",
    "print('\\t{}: {}'.format(key, value.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning for all greetings:')\n",
    "partial_rows = table.read_rows()\n",
    "partial_rows.consume_all()\n",
    "\n",
    "for row_key, row in partial_rows.rows.items():\n",
    "    key = row_key.decode('utf-8')\n",
    "    cell = row.cells[column_family_name][column_name][0]\n",
    "    value = cell.value.decode('utf-8')\n",
    "    print('\\t{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Using Happybase Client:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud Client Library.\n",
    "from google.cloud import happybase\n",
    "\n",
    "# The client must be created with admin=True because it will create a table.\n",
    "\n",
    "#client     = bigtable.Client(project=project_id, admin=True)\n",
    "client = bigtable.Client(admin=True)\n",
    "instance   = client.instance(instance_id)\n",
    "connection = happybase.Connection(instance=instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didn't receive an error, it means that at this point we're connected to our Bigtable database.<rb>\n",
    "\n",
    "#### <span style=\"color:Green\">Let's create a table:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name  = \"greetings2\"\n",
    "print('Creating the {} table.'.format(table_name))\n",
    "column_family_name = 'cf1'\n",
    "connection.create_table(    table_name,\n",
    "                            {\n",
    "                                column_family_name: dict()     # Use default options.\n",
    "                            }\n",
    "                       )\n",
    "### WARNING\n",
    "#\n",
    "## You will get an error the first time saying that you did not enable admin api. \n",
    "## A link will be given. Follow it and enable the API And retry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Now we insert data:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Writing some greetings to the table.')\n",
    "table = connection.table(table_name)\n",
    "column_name = '{fam}:greeting'.format(fam=column_family_name)\n",
    "greetings = [\n",
    "    'Hello World!',\n",
    "    'Hello Cloud Bigtable!',\n",
    "    'Hello HappyBase!',\n",
    "]\n",
    "\n",
    "for i, value in enumerate(greetings):\n",
    "    row_key = 'greeting{}'.format(i)\n",
    "    table.put(row_key, {(column_name).encode('utf-8'): value.encode('utf-8')})\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">And now we read the data back:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting a single greeting by row key.')\n",
    "key = 'greeting0'.encode('utf-8')\n",
    "row = table.row(key)\n",
    "print('\\t{}: {}'.format(key, row[column_name.encode('utf-8')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning for all greetings:')\n",
    "\n",
    "for key, row in table.scan():\n",
    "    print('\\t{}: {}'.format(key, row[column_name.encode('utf-8')]))\n",
    "\n",
    "#     print('Deleting the {} table.'.format(table_name))\n",
    "#     connection.delete_table(table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">Finally let's insert some more interesting data; here we will use the bigtable client but it can be done using happybase too:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from time import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Measures        = pd.read_csv(\"radiation.measurements.sample.csv\",keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Measures   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The client must be created with admin=True because it will create a table.\n",
    "client     = bigtable.Client(admin=True)\n",
    "instance   = client.instance(instance_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name  = \"RadiationMeasurements\"\n",
    "table_columns = [\n",
    "                    (\"time\",\"Captured Time\"),(\"time\",\"Uploaded Time\"),\n",
    "                    (\"location\",\"Latitude\"),(\"location\",\"Longitude\"),(\"location\",\"Height\"),\n",
    "                    (\"measure\",\"Value\"),(\"measure\",\"Unit\"),\n",
    "                    (\"device\",\"Device ID\")\n",
    "                ]\n",
    "\n",
    "print('Creating the {} table.'.format(table_name))\n",
    "\n",
    "RadiationMeasurements = instance.table(table_name)\n",
    "RadiationMeasurements.create()\n",
    "\n",
    "\n",
    "columnFamilies = []\n",
    "for aColumn in table_columns:\n",
    "    columnFamilies.append(aColumn[0])\n",
    "columnFamilies = list(set(columnFamilies))\n",
    "\n",
    "for aColumnFamily in columnFamilies:\n",
    "    cf = RadiationMeasurements.column_family(aColumnFamily)\n",
    "    cf.create()\n",
    "     \n",
    "\n",
    "print(\"done!\")\n",
    "### WARNING\n",
    "#\n",
    "## You will get an error the first time saying that you did not enable admin api. \n",
    "## A link will be given. Follow it and enable the API And retry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnFamilies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_family_list = RadiationMeasurements.list_column_families()\n",
    "print(column_family_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RadiationMeasurements.delete()   #UNCOMMENT IF YOU NEED TO DROP THE TABLE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,dfRow in df_Measures.iterrows():\n",
    "    row_key = 'measurement_{}'.format(index)\n",
    "    row = RadiationMeasurements.row(row_key)\n",
    "    \n",
    "\n",
    "    for aColumn in table_columns:  #([0],[1]) maps to (columnFamily,columnName)\n",
    "        row.set_cell(   \n",
    "                        aColumn[0],\n",
    "                        aColumn[1],\n",
    "                        str(dfRow[aColumn[1]]).encode('utf-8')\n",
    "                    )\n",
    "    row.commit()\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning 5 Measurements:')\n",
    "partial_rows = RadiationMeasurements.read_rows(limit=5)\n",
    "partial_rows.consume_all()\n",
    "for row_key, row in partial_rows.rows.items():\n",
    "    key   = row_key.decode('utf-8')\n",
    "    rowArr = []\n",
    "    for aColumn in table_columns:\n",
    "        rowArr.append(row.cells[aColumn[0]][aColumn[1].encode(\"utf-8\")][0].value)\n",
    "    print(\"Key:\",key)\n",
    "    for i in range(len(table_columns)):\n",
    "        print(\"Data:\",table_columns[i][0],table_columns[i][1],\":\",rowArr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scanning measurement 3 to 5:')\n",
    "partial_rows = RadiationMeasurements.read_rows(start_key=\"measurement_3\",end_key=\"measurement_5\")\n",
    "partial_rows.consume_all()\n",
    "\n",
    "for row_key, row in partial_rows.rows.items():\n",
    "    key   = row_key.decode('utf-8')\n",
    "    rowArr = []\n",
    "    for aColumn in table_columns:\n",
    "        rowArr.append(row.cells[aColumn[0]][aColumn[1].encode(\"utf-8\")][0].value)\n",
    "    print(\"Key:\",key)\n",
    "    for i in range(len(table_columns)):\n",
    "        print(\"      Data:\",table_columns[i][0],table_columns[i][1],\":\",rowArr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION:\n",
    "**_In which line are the data actually fetched from Bigtable?_** Explain briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> --- Answer HERE --- </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sum all Measurements that the unit is cpm:')\n",
    "\n",
    "###############\n",
    "####    TO DO HERE\n",
    "##############\n",
    "\n",
    "print (\"The sum is:\", totalSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#5DB664\">DELETE YOUR Bigtable INSTANCE AS WHEN YOU FINISH WITH REVIEW OF THE ABOVE EXAMPLE!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 1px solid red; margin-top: 20px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "# <span style=\"color:RED\">Exercise: </span> New York City - Buildings Dataset\n",
    "\n",
    "<hr style=\"border-top: 1px solid red; margin-top: 20px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "Similar to the example above, we are going to be using the New York City - Buildings competition dataset available [here](https://www.kaggle.com/new-york-city/nyc-buildings/data). <br>\n",
    "You should:\n",
    "1. Download the dataset to your machine.\n",
    "2. Create a new database.\n",
    "3. Create the necessary tables to load the Brooklyn subset.\n",
    "4. Load the Brooklyn dataset, but be smart when uploading. If we don't have a value for a particular cell, don't load it into Bigtable.\n",
    "\n",
    "\n",
    "## Questions:\n",
    "1. Report the time for loading the dataset.\n",
    "2. Generate a report that for each zipcode displays the average of the lot and building front area. <br>\n",
    "In this query the performance is very important as you are reading a noticeable ammount of data. Come up with an initial procedure to solve the query. Later try to improve that code. Did your second implementation improve the running time? Explain why. Present the code used in both stages and the runtime for each one. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACE YOUR CODE STARTING THIS POINT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "Submission: Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the submit cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can go to the URL that you got at the very beginning of this homework and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
